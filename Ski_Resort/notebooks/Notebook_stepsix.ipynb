{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n",
       "\n",
       "// needed to generate the Table of contents \n",
       "// taken from github.com/kmahelona/ipython_notebook_goodies\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n",
    "\n",
    "// needed to generate the Table of contents \n",
    "// taken from github.com/kmahelona/ipython_notebook_goodies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cf5CmXQCZyF1"
   },
   "source": [
    "# Guided Capstone Step 6. Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbZXsVevfr9M"
   },
   "source": [
    "**The Data Science Method**  \n",
    "\n",
    "\n",
    "1.   Problem Identification \n",
    "\n",
    "2.   Data Wrangling \n",
    "  \n",
    "3.   Exploratory Data Analysis \n",
    " \n",
    "4.   Pre-processing and Training Data Development\n",
    "\n",
    "5.  Modeling\n",
    "\n",
    "6.   **Documentation**\n",
    "  * Review the Results\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation\n",
    "  * Create a Project Report \n",
    "  * Create a Slide Deck for the Executive Audience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-oGciwnGUYk"
   },
   "source": [
    "In this guided capstone we are going to revisit many of the actions we took in the previous guided capstone steps. This gives you the opportunity to practice the code you wrote to solve the questions in step 4 and 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8xfkAqqZyF2"
   },
   "source": [
    "**<font color='teal'> Start by loading the necessary packages and printing out our current working directory just to confirm we are in the correct project directory. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ry6WPL5eZyF3"
   },
   "outputs": [],
   "source": [
    "#load python packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andrea/Dropbox/PyProjects/Springboard/Ski_Resort\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../\") \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0HTP9cF2GUYs"
   },
   "source": [
    "## Fit Models with Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A2FmSbtCGUYt"
   },
   "source": [
    "**<font color='teal'> Using sklearn fit the model you chose in Guided Capstone 5 on your training dataset. This includes: creating dummy features for states if you need them, scaling the data,and creating train and test splits before fitting the chosen model.Also, remember to generate a model performance score(MAE, or explained variance) based on the testing hold-out data set.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ReRSy1yFGUYu"
   },
   "source": [
    "#### Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dict to collect model performance data\n",
    "models_comparison = {'Model': [],\n",
    "        'Explained Variance': [],\n",
    "        'Mean Absolute Error': [],\n",
    "        'Features Dropped': []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRhPGbqPGUYv"
   },
   "outputs": [],
   "source": [
    "#Loading data\n",
    "filename = 'data/interim/step3_output.csv'\n",
    "\n",
    "df = pd.read_csv(filename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# first we import the preprocessing package from the sklearn library\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# I # dropping 'Name', 'state' because they are irrelevant to the prediction\n",
    "# dropping 'AdultWeekend' beacuse it's my response variable\n",
    "var_to_exclude = ['Name', 'state']\n",
    "\n",
    "# Declare an explanatory variable, called X\n",
    "# dropping 'AdultWeekend' beacuse it's my response variable\n",
    "X = df.drop(var_to_exclude + ['AdultWeekend'], axis=1)\n",
    "print(type(X))\n",
    "\n",
    "# Declare a response variable, called y, \n",
    "# Assign it the AdultWeekend column of the df \n",
    "\n",
    "y = df.loc[:,'AdultWeekend'] \n",
    "print(type(y))\n",
    "\n",
    "# Use the StandardScaler() method of the preprocessing package, and then call the fit() method with parameter X \n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "# Declare a variable called X_scaled, and assign it the result of calling the transform() method with parameter X \n",
    "X_scaled=scaler.transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_split function from the sklearn.model_selection utility.  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the 1-dimensional flattened array of our response variable y by calling the ravel() function on y\n",
    "y = y.ravel()\n",
    "\n",
    "# Call the train_test_split() function with the first two parameters set to X_scaled and y \n",
    "# Declare four variables, X_train, X_test, y_train and y_test separated by commas \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all model 2 set\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import explained_variance_score,mean_absolute_error\n",
    "lm = linear_model.LinearRegression()\n",
    "model2 = lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a variable called y_pred and assign it the result of calling predict() on our model variable with parameter X_test\n",
    "y_pred = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance :  0.6173858044944314\n",
      "MAE :  7.002704792077622\n",
      "Intercept :  56.89781265626314\n"
     ]
    }
   ],
   "source": [
    "print('Explained Variance : ', explained_variance_score(y_test, y_pred))\n",
    "print('MAE : ', mean_absolute_error(y_test, y_pred))\n",
    "print('Intercept : ', lm.intercept_)\n",
    "\n",
    "#Add Values to dict\n",
    "models_comparison['Model'].append('Model 2')\n",
    "models_comparison['Explained Variance'].append(explained_variance_score(y_test, y_pred))\n",
    "models_comparison['Mean Absolute Error'].append(mean_absolute_error(y_test, y_pred))\n",
    "models_comparison['Features Dropped'].append(var_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(models_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdultWeekday</th>\n",
       "      <td>9.792263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vertical_drop</th>\n",
       "      <td>3.424301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clusters</th>\n",
       "      <td>3.214312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>averageSnowfall</th>\n",
       "      <td>2.359921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit_elev</th>\n",
       "      <td>2.201206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <td>1.995920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkiableTerrain_ac</th>\n",
       "      <td>1.873452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quad</th>\n",
       "      <td>1.552902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triple</th>\n",
       "      <td>1.460332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <td>1.369666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Coefficient\n",
       "AdultWeekday          9.792263\n",
       "vertical_drop         3.424301\n",
       "clusters              3.214312\n",
       "averageSnowfall       2.359921\n",
       "summit_elev           2.201206\n",
       "daysOpenLastYear      1.995920\n",
       "SkiableTerrain_ac     1.873452\n",
       "quad                  1.552902\n",
       "triple                1.460332\n",
       "projectedDaysOpen     1.369666"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame displaying the coefficients for each state\n",
    "M2_coefficients_df = pd.DataFrame(abs(lm.coef_), X.columns, columns=['Coefficient'])\n",
    "# Print the top 10 coefficient values in descending order\n",
    "M2_coefficients_df.sort_values(by='Coefficient', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might want to make a pandas DataFrame displaying the coefficients for each state like so: \n",
    "M2_coefficients_df = pd.DataFrame(abs(lm.coef_), X.columns, columns=['Coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summit_elev</th>\n",
       "      <td>2.201206e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vertical_drop</th>\n",
       "      <td>3.424301e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trams</th>\n",
       "      <td>8.881784e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastEight</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastSixes</th>\n",
       "      <td>1.332268e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastQuads</th>\n",
       "      <td>6.599842e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quad</th>\n",
       "      <td>1.552902e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triple</th>\n",
       "      <td>1.460332e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>double</th>\n",
       "      <td>7.105196e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surface</th>\n",
       "      <td>7.101964e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_chairs</th>\n",
       "      <td>9.305746e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Runs</th>\n",
       "      <td>9.985902e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TerrainParks</th>\n",
       "      <td>1.140594e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LongestRun_mi</th>\n",
       "      <td>6.891317e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkiableTerrain_ac</th>\n",
       "      <td>1.873452e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow Making_ac</th>\n",
       "      <td>1.026491e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysOpenLastYear</th>\n",
       "      <td>1.995920e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearsOpen</th>\n",
       "      <td>4.124711e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>averageSnowfall</th>\n",
       "      <td>2.359921e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdultWeekday</th>\n",
       "      <td>9.792263e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projectedDaysOpen</th>\n",
       "      <td>1.369666e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NightSkiing_ac</th>\n",
       "      <td>3.133657e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clusters</th>\n",
       "      <td>3.214312e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Coefficient\n",
       "summit_elev        2.201206e+00\n",
       "vertical_drop      3.424301e+00\n",
       "trams              8.881784e-16\n",
       "fastEight          0.000000e+00\n",
       "fastSixes          1.332268e-15\n",
       "fastQuads          6.599842e-01\n",
       "quad               1.552902e+00\n",
       "triple             1.460332e+00\n",
       "double             7.105196e-01\n",
       "surface            7.101964e-01\n",
       "total_chairs       9.305746e-01\n",
       "Runs               9.985902e-03\n",
       "TerrainParks       1.140594e+00\n",
       "LongestRun_mi      6.891317e-01\n",
       "SkiableTerrain_ac  1.873452e+00\n",
       "Snow Making_ac     1.026491e+00\n",
       "daysOpenLastYear   1.995920e+00\n",
       "yearsOpen          4.124711e-01\n",
       "averageSnowfall    2.359921e+00\n",
       "AdultWeekday       9.792263e+00\n",
       "projectedDaysOpen  1.369666e+00\n",
       "NightSkiing_ac     3.133657e-01\n",
       "clusters           3.214312e+00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2_coefficients_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GGizyeLZGUYz"
   },
   "source": [
    "## Review the results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Lhu-qisGUY0"
   },
   "source": [
    "**<font color='teal'> Now, let's predict the Big Mountain Weekend price with our model in order to provide a recommendation to our managers on how to price the `AdultWeekend` lift ticket. First we need to find the row for Big Mountain resort in our data using string contains or string matching.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YXnx_IuEGUY1"
   },
   "outputs": [],
   "source": [
    "#df[df['Name'].str.contains('Big Mountain')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83-jO9hPGUY4"
   },
   "source": [
    "**<font color='teal'> Prepare the Big Mountain resort data row as you did in the model fitting stage.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWH_q9YOGUY5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2BCFqZYBGUY9"
   },
   "source": [
    "**<font color='teal'> Predict the Big Mountain resort `Adult Weekend` price and print it out.</font>** This is our expected price to present to management. Based on our model given the characteristics of the resort in comparison to other ski resorts and their unique characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XebWxxTMGUY-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5BvguMLGUZB"
   },
   "source": [
    "**<font color='teal'> Print the Big Mountain resort actual `Adult Weekend` price.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WyxTHtL2GUZC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0Yli8MXGUZH"
   },
   "source": [
    "**<font color='teal'> As part of reviewing the results it is an important step to generate figures to visualize the data story. We can use the clusters we added to our data frame to create scatter plots for visualizing the Adult Weekend values compared to other characteristics. Run the example below to get you started and build two or three more figures to include in your data story telling.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWtr873fGUZI"
   },
   "outputs": [],
   "source": [
    "#plt.scatter(df['summit_elev'], df['vertical_drop'], c=df['clusters'], s=50, cmap='viridis', label ='clusters')\n",
    "#plt.scatter(ac['summit_elev'], ac['vertical_drop'], c='black', s=100)\n",
    "#plt.xlabel('summit_elev')\n",
    "#plt.ylabel('vertical_drop')\n",
    "#plt.title('summit_elev by vertical_drop by cluster')\n",
    "#plt.savefig('figures/fig1.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "530JtuJxGUZL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGvf4kTwGUZR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYZB84hYGUZU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "giLKE2WMGUZh"
   },
   "source": [
    "## Finalize Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pps_ASHoGUZi"
   },
   "source": [
    " Making sure our code is well organized and easy to follow is an important step. This is the time where you need to review the notebooks and Python scripts you've created and clean them up so they are easy to follow and succinct in nature. Addtionally, we will also save our final model as a callable object using Pickle for future use in a data pipeline. Pickle is a module that serializes (and de-serializes) Python objects so that they can become executable objects like functions. It's used extensively in production environments where machine learning models are deployed on an industrial scale!**<font color='teal'> Run the example code below to save out your callable model. Notice that we save it in the models folder we created in our previous guided capstone step.</font>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_h0tkt_GUZj"
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#s = pickle.dumps(model)\n",
    "#from joblib import dump, load\n",
    "#dump(model, 'models/regression_model_adultweekend.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MTVrVlerGUZn"
   },
   "source": [
    "## Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thEMyu-DGUZo"
   },
   "source": [
    "For model documentation, we want to save the model performance metrics as well as the features included in the final model. You could also save the model perfomance metrics and coefficients fo the other models you tried in case you want to refer to them later. **<font color='teal'> Create a dataframe containing the coefficients and the model performance metrics and save it out as a csv file, then upload it to your github repository.</font>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "278tnHLlGUZp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CEOoBLFGUZr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RtEspslPZyGY",
    "s0DokMkAZyGc",
    "2iuitnKcZyHS",
    "iAWQxougZyHW",
    "ThMTimlBZyHZ",
    "QwZ-LkjXZyHt",
    "srtXEA3N4-Y9",
    "ChVreJupZyIA",
    "zDgSSsq1ZyID",
    "I3GYKWfi5Llg",
    "pmMvrhbI-viE",
    "ZXDPkW3UZyIX",
    "Dnc_vHQLZyId",
    "daJxuJ-dZyIg",
    "mAQ-oHiPZyIn",
    "hnGOsp3mZyIp"
   ],
   "name": "GuidedCapstoneStep6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:TestEnv]",
   "language": "python",
   "name": "conda-env-TestEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
