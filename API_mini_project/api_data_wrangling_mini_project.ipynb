{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will require you to pull some data from the Qunadl API. Qaundl is currently the most widely used aggregator of financial market data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will need to register a free account on the http://www.quandl.com website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you register, you will be provided with a unique API key, that you should store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Store the API key as a string - according to PEP8, constants are always named in all upper case\n",
    "\n",
    "#API_KEY = 'your-key-here'\n",
    "\n",
    "# Import QUANDL_API_KEY from the .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "import os\n",
    "API_KEY = os.getenv(\"QUANDL_API_KEY\")\n",
    "\n",
    "print(type(API_KEY))\n",
    "#print(API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qaundl has a large number of data sources, but, unfortunately, most of them require a Premium subscription. Still, there are also a good number of free datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this mini project, we will focus on equities data from the Frankfurt Stock Exhange (FSE), which is available for free. We'll try and analyze the stock prices of a company called Carl Zeiss Meditec, which manufactures tools for eye examinations, as well as medical lasers for laser eye surgery: https://www.zeiss.com/meditec/int/home.html. The company is listed under the stock ticker AFX_X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the detailed Quandl API instructions here: https://docs.quandl.com/docs/time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a dedicated Python package for connecting to the Quandl API, we would prefer that you use the *requests* package, which can be easily downloaded using *pip* or *conda*. You can find the documentation for the package here: http://docs.python-requests.org/en/master/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apart from the *requests* package, you are encouraged to not use any third party Python packages, such as *pandas*, and instead focus on what's available in the Python Standard Library (the *collections* module might come in handy: https://pymotw.com/3/collections/ ).\n",
    "Also, since you won't have access to DataFrames, you are encouraged to us Python's native data structures - preferably dictionaries, though some questions can also be answered using lists.\n",
    "You can read more on these data structures here: https://docs.python.org/3/tutorial/datastructures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the JSON responses you will be getting from the API map almost one-to-one to Python's dictionaries. Unfortunately, they can be very nested, so make sure you read up on indexing dictionaries in the documentation provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the relevant modules\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a sample API Call for 1 day worth of data\n",
    "\n",
    "#get yesterday's date with datetime and timedelta modules\n",
    "yesterday = datetime.now() - timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set API call parameters\n",
    "database_code = 'FSE' # Frankfurt Stock Exchange Database\n",
    "dataset_code = 'AFX_X' #Ticker symbol for Carl Zeiss Meditec\n",
    "start_date = yesterday.strftime('%Y-%m-%d') #convert to string and format to yyyy-mm-dd\n",
    "\n",
    "url = 'https://www.quandl.com/api/v3/datasets/'+database_code+'/'+dataset_code+'/data.json'\n",
    "\n",
    "payload = {'api_key': API_KEY, 'start_date': start_date}\n",
    "\n",
    "r = requests.get(url, params=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover']\n"
     ]
    }
   ],
   "source": [
    "# Inspect the JSON structure of the object you created, and take note of how nested it is,\n",
    "# as well as the overall structure\n",
    "r_dict = r.json()\n",
    "#print(r_dict)\n",
    "#print(r_dict['dataset_data'])\n",
    "print(r_dict['dataset_data']['column_names'])\n",
    "#print(r_dict['dataset_data']['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are your tasks for this mini project:\n",
    "\n",
    "1. Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect Data for 2017\n",
    "# set API call parameters\n",
    "database_code = 'FSE' # Frankfurt Stock Exchange Database\n",
    "dataset_code = 'AFX_X' #Ticker symbol for Carl Zeiss Meditec\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2017-12-31'\n",
    "\n",
    "url = 'https://www.quandl.com/api/v3/datasets/'+database_code+'/'+dataset_code+'/data.json'\n",
    "\n",
    "payload = {'api_key': API_KEY, 'start_date': start_date, 'end_date': end_date}\n",
    "\n",
    "r = requests.get(url, params=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert the returned JSON object into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the respnse data to a dict\n",
    "d = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = d['dataset_data']['data'] #extract the List of lists Data from the dict for processing\n",
    "#print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract relevant variables opening, high, low, closing, trading volume respectively at colums of indices 1,2,3,4,6 of the list\n",
    "opening = []\n",
    "closing = []\n",
    "high = []\n",
    "low = []\n",
    "trading_vol = []\n",
    "\n",
    "for l in lst :\n",
    "    #print(l[1])\n",
    "    opening.append(l[1])  \n",
    "    high.append(l[2])\n",
    "    low.append(l[3])\n",
    "    closing.append(l[4])\n",
    "    trading_vol.append(l[6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate what the highest and lowest opening prices were for the stock in this period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe that opening has some missing values while closing doesn't\n",
    "#print(opening)\n",
    "#print(closing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This operation is redundant since I realized I was looking at the wrong timeframe which had None values\n",
    "# I'll keep it so if I need to change the timeframe I can still use this code.\n",
    "# How do we handle missing values?\n",
    "# We will replace the missing values in opening with the closing value for the same day.\n",
    "\n",
    "\n",
    "clean_opening = []\n",
    "for idx, val in enumerate(opening):\n",
    "    if val is None:\n",
    "        clean_opening.append(closing[idx])\n",
    "    else :\n",
    "        clean_opening.append(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that this worked correctly\n",
    "#print(clean_opening)\n",
    "#print(closing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The higest opening price for  AFX_X  in 2017 is:  53.11\n",
      "The lowest opening price for  AFX_X  in 2017 is:  34.0\n"
     ]
    }
   ],
   "source": [
    "highest_opening = max(clean_opening)\n",
    "lowest_opening = min(clean_opening)\n",
    "print('The higest opening price for ', dataset_code, ' in 2017 is: ', highest_opening)\n",
    "print('The lowest opening price for ', dataset_code, ' in 2017 is: ', lowest_opening)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What was the largest change in any one day (based on High and Low price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest daily change in any one day (based on High and Low price) for  AFX_X  in 2017 is:  2.81\n"
     ]
    }
   ],
   "source": [
    "hi_lo_change = []\n",
    "for idx, val in enumerate(high):\n",
    "    hi_lo_change.append(val-low[idx])\n",
    "    \n",
    "max_hi_lo_change = max(hi_lo_change)\n",
    "print('The largest daily change in any one day (based on High and Low price) for ', dataset_code, ' in 2017 is: ', round(max_hi_lo_change,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What was the largest change between any two days (based on Closing Price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change between any two days (based on Closing Price) for  AFX_X  in 2017 is:  2.56\n"
     ]
    }
   ],
   "source": [
    "day_daybefore_change = []\n",
    "for idx, val in enumerate(closing):\n",
    "    if idx == 0 :\n",
    "        day_daybefore_change.append(0)\n",
    "    else :\n",
    "        day_daybefore_change.append(val-closing[idx-1])\n",
    "        \n",
    "max_day_daybefore_change = max(day_daybefore_change)\n",
    "print('The largest change between any two days (based on Closing Price) for ', dataset_code, ' in 2017 is: ', round(max_day_daybefore_change,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What was the average daily trading volume during this year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This operation is redundant since I realized I was looking at the wrong timeframe which had None values\n",
    "# I'll keep it so if I need to change the timeframe I can still use this code.\n",
    "#Trading vol has some None values too. We will replace them with zero. \n",
    "#print(trading_vol)\n",
    "clean_trading_vol = []\n",
    "for idx, val in enumerate(trading_vol):\n",
    "    if val is None:\n",
    "        clean_trading_vol.append(0)\n",
    "    else :\n",
    "        clean_trading_vol.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average daily trading volume for  AFX_X  in 2017 is:  89124.34\n"
     ]
    }
   ],
   "source": [
    "avg_daily_trade_vol = sum(clean_trading_vol) / len(clean_trading_vol)\n",
    "print('The average daily trading volume for ', dataset_code, ' in 2017 is: ', round(avg_daily_trade_vol,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median trading volume for  AFX_X  in 2017 is:  76286.0\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "median_daily_trade_vol = statistics.median(clean_trading_vol)\n",
    "print('The median trading volume for ', dataset_code, ' in 2017 is: ', round(median_daily_trade_vol,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TestEnv]",
   "language": "python",
   "name": "conda-env-TestEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
