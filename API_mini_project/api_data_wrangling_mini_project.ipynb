{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will require you to pull some data from the Qunadl API. Qaundl is currently the most widely used aggregator of financial market data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will need to register a free account on the http://www.quandl.com website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you register, you will be provided with a unique API key, that you should store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Store the API key as a string - according to PEP8, constants are always named in all upper case\n",
    "\n",
    "#API_KEY = 'your-key-here'\n",
    "\n",
    "# Import QUANDL_API_KEY from the .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "import os\n",
    "API_KEY = os.getenv(\"QUANDL_API_KEY\")\n",
    "\n",
    "print(type(API_KEY))\n",
    "#print(API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qaundl has a large number of data sources, but, unfortunately, most of them require a Premium subscription. Still, there are also a good number of free datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this mini project, we will focus on equities data from the Frankfurt Stock Exhange (FSE), which is available for free. We'll try and analyze the stock prices of a company called Carl Zeiss Meditec, which manufactures tools for eye examinations, as well as medical lasers for laser eye surgery: https://www.zeiss.com/meditec/int/home.html. The company is listed under the stock ticker AFX_X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the detailed Quandl API instructions here: https://docs.quandl.com/docs/time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a dedicated Python package for connecting to the Quandl API, we would prefer that you use the *requests* package, which can be easily downloaded using *pip* or *conda*. You can find the documentation for the package here: http://docs.python-requests.org/en/master/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apart from the *requests* package, you are encouraged to not use any third party Python packages, such as *pandas*, and instead focus on what's available in the Python Standard Library (the *collections* module might come in handy: https://pymotw.com/3/collections/ ).\n",
    "Also, since you won't have access to DataFrames, you are encouraged to us Python's native data structures - preferably dictionaries, though some questions can also be answered using lists.\n",
    "You can read more on these data structures here: https://docs.python.org/3/tutorial/datastructures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the JSON responses you will be getting from the API map almost one-to-one to Python's dictionaries. Unfortunately, they can be very nested, so make sure you read up on indexing dictionaries in the documentation provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the relevant modules\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a sample API Call for 1 day worth of data\n",
    "\n",
    "#get yesterday's date with datetime and timedelta modules\n",
    "yesterday = datetime.now() - timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set API call parameters\n",
    "database_code = 'FSE' # Frankfurt Stock Exchange Database\n",
    "dataset_code = 'AFX_X' #Ticker symbol for Carl Zeiss Meditec\n",
    "start_date = yesterday.strftime('%Y-%m-%d') #convert to string and format to yyyy-mm-dd\n",
    "\n",
    "url = 'https://www.quandl.com/api/v3/datasets/'+database_code+'/'+dataset_code+'/data.json'\n",
    "\n",
    "payload = {'api_key': API_KEY, 'start_date': start_date}\n",
    "\n",
    "r = requests.get(url, params=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover']\n"
     ]
    }
   ],
   "source": [
    "# Inspect the JSON structure of the object you created, and take note of how nested it is,\n",
    "# as well as the overall structure\n",
    "r_dict = r.json()\n",
    "#print(r_dict)\n",
    "#print(r_dict['dataset_data'])\n",
    "print(r_dict['dataset_data']['column_names'])\n",
    "#print(r_dict['dataset_data']['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are your tasks for this mini project:\n",
    "\n",
    "1. Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect Data for 2017\n",
    "# set API call parameters\n",
    "database_code = 'FSE' # Frankfurt Stock Exchange Database\n",
    "dataset_code = 'AFX_X' #Ticker symbol for Carl Zeiss Meditec\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2017-12-31'\n",
    "\n",
    "url = 'https://www.quandl.com/api/v3/datasets/'+database_code+'/'+dataset_code+'/data.json'\n",
    "\n",
    "payload = {'api_key': API_KEY, 'start_date': start_date, 'end_date': end_date}\n",
    "\n",
    "r = requests.get(url, params=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert the returned JSON object into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the respnse data to a dict\n",
    "d = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = d['dataset_data']['data'] #extract the List of lists Data from the dict for processing\n",
    "#print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract relevant variables opening, high, low, closing, trading volume respectively at colums of indices 1,2,3,4,6 of the list\n",
    "opening = []\n",
    "closing = []\n",
    "high = []\n",
    "low = []\n",
    "trading_vol = []\n",
    "\n",
    "for l in lst :\n",
    "    #print(l[1])\n",
    "    opening.append(l[1])  \n",
    "    high.append(l[2])\n",
    "    low.append(l[3])\n",
    "    closing.append(l[4])\n",
    "    trading_vol.append(l[6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate what the highest and lowest opening prices were for the stock in this period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51.76, 51.65, 51.45, 51.05, 51.16, 51.88, 52.73, 52.37, 52.7, 53.11, 52.64, 52.29, 52.28, 51.5, 50.89, 50.8, 51.21, 49.5, 49.52, 48.64, 49.64, 49.09, 49.13, 49.11, 48.8, 48.4, 47.25, 46.57, 47.03, 47.09, 47.98, 48.4, 48.38, 47.3, 47.65, 46.42, 46.16, 45.81, 45.0, 45.88, 46.29, 46.53, 45.48, 45.2, 45.01, 45.16, 44.9, 45.08, 45.72, 46.01, 45.8, 45.61, 45.5, 45.58, 45.97, 45.64, 46.2, 46.19, 46.01, 45.36, 44.51, 43.58, 42.0, 42.35, 42.3, 42.3, 41.48, 42.29, 42.54, 42.65, 42.5, 42.29, 42.35, 42.49, 43.21, 42.81, 42.7, 43.0, 42.66, 43.0, 42.38, 42.16, 42.0, 42.0, 41.71, 42.11, 42.64, 42.72, 42.82, 42.46, 42.42, 42.28, 41.88, 42.4, 42.53, 42.12, 41.3, 41.73, 43.5, 44.9, 45.85, 45.13, 45.34, 45.25, 45.24, 44.94, 45.26, 45.16, 44.91, 44.7, 45.31, 45.57, 45.74, 45.06, 45.5, 45.6, 45.07, 44.67, 44.29, 44.94, 44.64, 44.79, 45.5, 44.67, 45.83, 45.29, 45.01, 45.73, 46.68, 47.23, 46.95, 47.29, 47.03, 47.46, 46.48, 46.9, 45.66, 46.34, 46.52, 46.5, 47.31, 46.77, 47.8, 47.01, 47.12, 46.8, 46.12, 45.22, 45.05, 45.61, 44.8, 44.8, 43.92, 43.67, 44.16, 43.74, 44.0, 45.06, 45.15, 45.09, 45.18, 43.4, 43.5, 41.83, 43.0, 42.52, 41.86, 42.2, 41.89, None, 42.17, 41.51, 41.88, 41.93, 42.01, 41.97, 42.5, 41.94, 42.24, None, None, 42.06, 42.02, 41.62, 41.46, 40.9, 40.96, 41.1, 39.5, 40.15, 39.77, 40.02, 39.39, 38.95, 38.73, 38.94, 39.01, 38.25, 41.8, 41.26, 41.47, 41.4, 41.4, 41.2, 41.4, 41.53, 41.61, 41.13, 41.5, 41.25, 41.12, 41.38, 41.19, 40.38, 39.75, 39.77, 39.72, 39.6, 38.85, 39.25, 38.8, 38.8, 38.5, 38.81, 37.37, 36.65, 36.2, 35.98, 35.56, 36.06, 36.02, 35.95, 34.75, 35.24, 35.38, 34.83, 35.07, 34.42, 34.0, 34.04, 34.54, 35.04, 35.04, 35.06, 34.85, 34.98, 35.38, 34.95, 34.8, 35.29, 34.91, 35.02, 35.48, 35.9, 34.99]\n",
      "[51.76, 51.6, 51.82, 51.32, 51.4, 51.27, 51.66, 52.62, 52.01, 52.67, 53.09, 52.43, 52.14, 52.12, 51.47, 50.89, 51.25, 51.14, 49.86, 49.7, 48.75, 49.25, 49.2, 49.11, 49.2, 48.8, 48.39, 47.04, 46.84, 47.03, 47.05, 48.0, 48.34, 48.34, 47.21, 47.47, 46.26, 45.99, 45.97, 45.27, 46.04, 45.76, 46.41, 45.41, 45.0, 44.85, 45.0, 44.87, 45.0, 45.77, 45.96, 45.55, 45.4, 45.43, 45.29, 45.84, 45.74, 46.0, 46.05, 46.11, 44.98, 44.17, 43.56, 42.04, 42.37, 42.07, 42.06, 41.46, 41.99, 42.44, 42.27, 42.42, 42.52, 42.45, 42.73, 42.85, 42.67, 42.77, 42.55, 42.62, 42.6, 42.41, 41.9, 41.94, 41.85, 41.91, 42.14, 42.69, 42.71, 42.71, 42.26, 42.41, 42.5, 42.05, 42.28, 42.3, 41.94, 41.68, 41.81, 44.37, 44.96, 45.07, 44.97, 45.56, 45.45, 45.3, 44.97, 45.25, 45.16, 44.82, 44.61, 45.44, 45.66, 45.57, 45.0, 45.6, 45.53, 44.95, 44.95, 44.2, 44.7, 44.53, 44.62, 45.19, 44.8, 45.75, 45.44, 45.2, 45.68, 46.83, 47.21, 46.99, 47.29, 46.99, 47.37, 46.64, 46.63, 45.67, 46.33, 46.32, 46.31, 47.44, 46.27, 47.43, 47.43, 46.99, 46.52, 45.86, 46.02, 45.32, 45.3, 44.78, 44.53, 43.9, 43.84, 44.12, 43.98, 44.19, 45.31, 45.14, 44.99, 45.0, 43.28, 43.3, 42.24, 42.75, 42.5, 41.9, 42.15, 41.72, 41.72, 42.16, 41.5, 41.89, 41.81, 41.32, 41.93, 42.61, 42.0, 42.2, 42.2, 42.2, 42.2, 41.75, 41.68, 41.42, 41.05, 41.1, 40.81, 39.64, 39.98, 39.75, 40.01, 39.22, 38.85, 38.94, 38.96, 38.94, 40.98, 41.97, 41.34, 41.46, 41.25, 41.3, 41.3, 41.4, 41.4, 41.68, 41.42, 41.4, 41.18, 41.17, 41.2, 40.84, 40.39, 39.74, 39.79, 39.7, 39.45, 38.98, 39.02, 38.71, 38.72, 38.37, 38.53, 37.06, 36.25, 36.05, 35.89, 35.64, 36.1, 36.07, 35.94, 34.56, 35.15, 35.3, 34.89, 34.83, 34.22, 34.06, 34.17, 34.5, 34.9, 34.99, 35.07, 34.85, 34.9, 35.42, 34.91, 34.67, 35.04, 35.06, 35.19, 35.48, 35.8]\n"
     ]
    }
   ],
   "source": [
    "# We observe that opening has some missing values while closing doesn't\n",
    "#print(opening)\n",
    "#print(closing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we handle missing values?\n",
    "# We will replace the missing values in opening with the closing value for the same day.\n",
    "\n",
    "clean_opening = []\n",
    "for idx, val in enumerate(opening):\n",
    "    if val is None:\n",
    "        clean_opening.append(closing[idx])\n",
    "    else :\n",
    "        clean_opening.append(val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that this worked correctly\n",
    "#print(clean_opening)\n",
    "#print(closing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The higest opening price for  AFX_X  since  2017-01-01  is:  121.4\n",
      "The lowest opening price for  AFX_X  since  2017-01-01  is:  34.0\n"
     ]
    }
   ],
   "source": [
    "highest_opening = max(clean_opening)\n",
    "lowest_opening = min(clean_opening)\n",
    "print('The higest opening price for ', dataset_code, ' since ', start_date,' is: ', highest_opening)\n",
    "print('The lowest opening price for ', dataset_code, ' since ', start_date,' is: ', lowest_opening)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What was the largest change in any one day (based on High and Low price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest daily change in any one day (based on High and Low price) for  AFX_X  since  2017-01-01  is:  14.1\n"
     ]
    }
   ],
   "source": [
    "hi_lo_change = []\n",
    "for idx, val in enumerate(high):\n",
    "    hi_lo_change.append(val-low[idx])\n",
    "    \n",
    "max_hi_lo_change = max(hi_lo_change)\n",
    "print('The largest daily change in any one day (based on High and Low price) for ', dataset_code, ' since ', start_date,' is: ', round(max_hi_lo_change,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What was the largest change between any two days (based on Closing Price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change between any two days (based on Closing Price) for  AFX_X  since  2017-01-01  is:  8.95\n"
     ]
    }
   ],
   "source": [
    "day_daybefore_change = []\n",
    "for idx, val in enumerate(closing):\n",
    "    if idx == 0 :\n",
    "        day_daybefore_change.append(0)\n",
    "    else :\n",
    "        day_daybefore_change.append(val-closing[idx-1])\n",
    "        \n",
    "max_day_daybefore_change = max(day_daybefore_change)\n",
    "print('The largest change between any two days (based on Closing Price) for ', dataset_code, ' since ', start_date,' is: ', round(max_day_daybefore_change,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What was the average daily trading volume during this year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trading vol has some None values too. We will replace them with zero. \n",
    "#print(trading_vol)\n",
    "clean_trading_vol = []\n",
    "for idx, val in enumerate(trading_vol):\n",
    "    if val is None:\n",
    "        clean_trading_vol.append(0)\n",
    "    else :\n",
    "        clean_trading_vol.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The laverage daily trading volume for  AFX_X  since  2017-01-01  is:  118208.35\n"
     ]
    }
   ],
   "source": [
    "avg_daily_trade_vol = sum(clean_trading_vol) / len(clean_trading_vol)\n",
    "print('The laverage daily trading volume for ', dataset_code, ' since ', start_date,' is: ', round(avg_daily_trade_vol,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TestEnv]",
   "language": "python",
   "name": "conda-env-TestEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
